{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREO_voila_download.ipynb\n",
    "# Scraper creokitchens.it con interfaccia ipywidgets + download ZIP\n",
    "\n",
    "import os, io, time, csv, zipfile, shutil, traceback\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "BASE_URL   = \"https://www.creokitchens.it/it/cucine\"\n",
    "SITE_ROOT  = \"https://www.creokitchens.it\"\n",
    "OUTPUT_DIR = \"./creo_cucine\"\n",
    "ZIP_PATH   = \"./creo_cucine.zip\"\n",
    "\n",
    "USER_AGENT = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122 Safari/537.36 (+personal non-commercial scraping)\"\n",
    "REQUEST_TIMEOUT = (10, 25)\n",
    "SLEEP_BETWEEN_REQUESTS = 0.3\n",
    "MAX_IMAGE_BYTES = 40 * 1024 * 1024\n",
    "GLOBAL_PER_PAGE_TIMEOUT = 120\n",
    "\n",
    "# ------- SESSION -------\n",
    "def build_session():\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": USER_AGENT})\n",
    "    retries = Retry(total=4, connect=4, read=4, backoff_factor=0.5,\n",
    "                    status_forcelist=[429,500,502,503,504],\n",
    "                    allowed_methods=frozenset([\"GET\",\"HEAD\"]))\n",
    "    adapter = HTTPAdapter(max_retries=retries, pool_connections=10, pool_maxsize=10)\n",
    "    s.mount(\"http://\", adapter); s.mount(\"https://\", adapter)\n",
    "    return s\n",
    "\n",
    "session = build_session()\n",
    "\n",
    "def slugify(text, maxlen=80):\n",
    "    import re\n",
    "    text = re.sub(r\"\\s+\", \" \", text or \"\").strip()\n",
    "    text = text.replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n",
    "    text = re.sub(r\"[^0-9A-Za-zÀ-ÖØ-öø-ÿ _\\-\\.\\(\\)]\", \"\", text)\n",
    "    text = text[:maxlen]\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text or \"senza_nome\"\n",
    "\n",
    "def get_soup(url):\n",
    "    try:\n",
    "        r = session.get(url, timeout=REQUEST_TIMEOUT)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        return BeautifulSoup(r.text, \"html.parser\")\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "def head_ok_image(url):\n",
    "    try:\n",
    "        hr = session.head(url, timeout=REQUEST_TIMEOUT, allow_redirects=True)\n",
    "        if hr.status_code >= 400:\n",
    "            return False\n",
    "        ct = (hr.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        if \"image\" not in ct:\n",
    "            return False\n",
    "        clen = hr.headers.get(\"Content-Length\")\n",
    "        if clen and clen.isdigit() and int(clen) > MAX_IMAGE_BYTES:\n",
    "            return False\n",
    "        return True\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "def infer_ext(url):\n",
    "    path = urlparse(url).path\n",
    "    ext = os.path.splitext(path)[1]\n",
    "    return ext.split(\"?\")[0] if (ext and len(ext) <= 5) else \".jpg\"\n",
    "\n",
    "def download_image(url, dest_path):\n",
    "    if not head_ok_image(url):\n",
    "        return False\n",
    "    try:\n",
    "        with session.get(url, stream=True, timeout=REQUEST_TIMEOUT) as r:\n",
    "            r.raise_for_status()\n",
    "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            total = 0\n",
    "            with open(dest_path, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=1024*64):\n",
    "                    if not chunk: continue\n",
    "                    f.write(chunk); total += len(chunk)\n",
    "                    if total > MAX_IMAGE_BYTES:\n",
    "                        return False\n",
    "        return True\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "# ---------- UI ----------\n",
    "out = widgets.Output()\n",
    "status = widgets.HTML(\"\")\n",
    "\n",
    "def log(s): \n",
    "    with out: print(str(s))\n",
    "\n",
    "listing = get_soup(BASE_URL)\n",
    "if not listing:\n",
    "    log(\"[ERRORE] Impossibile caricare la pagina elenco.\")\n",
    "    raise SystemExit\n",
    "\n",
    "def is_kitchen_detail_url(href_abs: str) -> bool:\n",
    "    try:\n",
    "        u = urlparse(href_abs)\n",
    "        if u.netloc != urlparse(SITE_ROOT).netloc or u.query or u.fragment:\n",
    "            return False\n",
    "        path = u.path\n",
    "        if not path.startswith(\"/it/cucine/\"): return False\n",
    "        seg = [s for s in path.split(\"/\") if s]\n",
    "        if len(seg) != 3: return False\n",
    "        if \".\" in seg[-1]: return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "slug2url = {}\n",
    "for a in listing.select(\"a.gb-item-link\"):\n",
    "    href = a.get(\"href\") or \"\"\n",
    "    abs_url = urljoin(BASE_URL, href)\n",
    "    if is_kitchen_detail_url(abs_url):\n",
    "        slug = urlparse(abs_url).path.rstrip(\"/\").split(\"/\")[-1]\n",
    "        slug2url.setdefault(slug, abs_url)\n",
    "\n",
    "resolved = []\n",
    "for slug, url in slug2url.items():\n",
    "    s = get_soup(url); time.sleep(0.02)\n",
    "    name = slugify(s.find(\"h1\").get_text(strip=True)) if (s and s.find(\"h1\")) else slugify(slug)\n",
    "    resolved.append((name, url))\n",
    "resolved.sort(key=lambda t: t[0].lower())\n",
    "\n",
    "checkboxes = [widgets.Checkbox(value=False, description=name, indent=False) for name, _ in resolved]\n",
    "select_all = widgets.ToggleButton(value=False, description=\"Seleziona/Deseleziona tutto\", icon=\"check\")\n",
    "btn_confirm = widgets.Button(description=\"Conferma selezione\", button_style=\"primary\", icon=\"check\")\n",
    "img_num = widgets.BoundedIntText(value=3, min=1, max=99, step=1, description=\"Immagini/cucina:\")\n",
    "btn_start = widgets.Button(description=\"Avvia download\", button_style=\"success\", icon=\"play\")\n",
    "\n",
    "box_checks = widgets.GridBox(\n",
    "    checkboxes,\n",
    "    layout=widgets.Layout(grid_template_columns=\"repeat(2, 48%)\", grid_gap=\"6px\")\n",
    ")\n",
    "\n",
    "def on_toggle_all(change):\n",
    "    for cb in checkboxes:\n",
    "        cb.value = select_all.value\n",
    "select_all.observe(on_toggle_all, 'value')\n",
    "\n",
    "selected_pairs = []\n",
    "\n",
    "def on_confirm_clicked(b):\n",
    "    global selected_pairs\n",
    "    chosen = [(name, url) for cb, (name, url) in zip(checkboxes, resolved) if cb.value]\n",
    "    if not chosen:\n",
    "        status.value = \"<span style='color:#b00'>Seleziona almeno una cucina.</span>\"\n",
    "        return\n",
    "    selected_pairs = chosen\n",
    "    status.value = f\"<span style='color:#060'>Selezionate {len(chosen)} cucine. Imposta il numero di immagini e premi 'Avvia download'.</span>\"\n",
    "    select_all.disabled = True\n",
    "    for cb in checkboxes: cb.disabled = True\n",
    "    img_num.layout.display = \"block\"\n",
    "    btn_start.layout.display = \"inline-block\"\n",
    "\n",
    "btn_confirm.on_click(on_confirm_clicked)\n",
    "\n",
    "img_num.layout.display = \"none\"\n",
    "btn_start.layout.display = \"none\"\n",
    "\n",
    "download_area = widgets.HTML(\"\")  # qui metteremo il bottone FileDownload\n",
    "\n",
    "def scrape_sync(b):\n",
    "    btn_start.disabled = True\n",
    "    btn_confirm.disabled = True\n",
    "    img_num.disabled = True\n",
    "\n",
    "    try:\n",
    "        if not selected_pairs:\n",
    "            log(\"[ERRORE] Nessuna cucina selezionata.\")\n",
    "            return\n",
    "\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "        log(f\"Avvio: {len(selected_pairs)} cucine | {img_num.value} immagini/cucina\")\n",
    "\n",
    "        manifest = []\n",
    "\n",
    "        for idx, (name, url) in enumerate(selected_pairs, 1):\n",
    "            start_t = time.time()\n",
    "            soup = get_soup(url)\n",
    "            if not soup:\n",
    "                log(f\"- {idx}/{len(selected_pairs)} {name}: pagina non caricata, salto.\")\n",
    "                continue\n",
    "\n",
    "            h1 = soup.find(\"h1\")\n",
    "            name2 = slugify(h1.get_text(strip=True)) if h1 else slugify(name)\n",
    "            kdir = os.path.join(OUTPUT_DIR, name2)\n",
    "            os.makedirs(kdir, exist_ok=True)\n",
    "\n",
    "            desc_container = soup.select_one(\".gb-text-and-link\")\n",
    "            paras = [p.get_text(\" \", strip=True) for p in (desc_container.find_all(\"p\") if desc_container else []) if p.get_text(\" \", strip=True)]\n",
    "            desc = \"\\n\\n\".join(paras).strip()\n",
    "            with io.open(os.path.join(kdir, \"descrizione.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(desc)\n",
    "\n",
    "            wrappers = soup.select(\".gb-media-wrapper\")\n",
    "            anchors = []\n",
    "            for w in wrappers:\n",
    "                anchors.extend(w.select(\"a.gb-item-link\"))\n",
    "\n",
    "            seen = set(); ordered = []\n",
    "            for a in anchors:\n",
    "                href = a.get(\"href\")\n",
    "                if not href: continue\n",
    "                abs_url = urljoin(url, href)\n",
    "                if abs_url.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\")) and abs_url not in seen:\n",
    "                    seen.add(abs_url)\n",
    "                    ordered.append(abs_url)\n",
    "                if len(ordered) >= img_num.value:\n",
    "                    break\n",
    "\n",
    "            saved = 0\n",
    "            for i, img_url in enumerate(ordered, 1):\n",
    "                if time.time() - start_t > GLOBAL_PER_PAGE_TIMEOUT:\n",
    "                    break\n",
    "                dest = os.path.join(kdir, f\"{i:02d}{infer_ext(img_url)}\")\n",
    "                if download_image(img_url, dest):\n",
    "                    saved += 1\n",
    "                time.sleep(0.1)\n",
    "\n",
    "            manifest.append({\"kitchen_name\": name2, \"url\": url, \"description_chars\": len(desc), \"images_saved\": saved})\n",
    "            log(f\"- {idx}/{len(selected_pairs)} {name2}: immagini trovate {len(ordered)}, salvate {saved}\")\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "        man_path = os.path.join(OUTPUT_DIR, \"manifest.csv\")\n",
    "        with io.open(man_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=[\"kitchen_name\",\"url\",\"description_chars\",\"images_saved\"])\n",
    "            w.writeheader(); w.writerows(manifest)\n",
    "\n",
    "        if os.path.exists(ZIP_PATH):\n",
    "            os.remove(ZIP_PATH)\n",
    "        with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "            for root, _, files in os.walk(OUTPUT_DIR):\n",
    "                for file in files:\n",
    "                    full = os.path.join(root, file)\n",
    "                    rel = os.path.relpath(full, OUTPUT_DIR)\n",
    "                    z.write(full, arcname=os.path.join(\"creo_cucine\", rel))\n",
    "\n",
    "        log(f\"[OK] ZIP pronto: {ZIP_PATH}\")\n",
    "\n",
    "        # --- pulsante FileDownload ---\n",
    "        def _zip_bytes():\n",
    "            with open(ZIP_PATH, \"rb\") as f:\n",
    "                return f.read()\n",
    "\n",
    "        btn_download = widgets.FileDownload(\n",
    "            data=_zip_bytes,\n",
    "            filename=os.path.basename(ZIP_PATH),\n",
    "            description=\"⬇️ Scarica ZIP\",\n",
    "            button_style=\"primary\",\n",
    "            icon=\"download\"\n",
    "        )\n",
    "        display(btn_download)\n",
    "\n",
    "    except Exception:\n",
    "        log(\"[ERRORE] Qualcosa è andato storto:\\n\" + traceback.format_exc())\n",
    "\n",
    "btn_start.on_click(scrape_sync)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Seleziona le cucine da scaricare</h3>\"),\n",
    "    select_all,\n",
    "    box_checks,\n",
    "    widgets.HBox([btn_confirm]),\n",
    "    widgets.HBox([img_num, btn_start]),\n",
    "    status,\n",
    "    widgets.HTML(\"<hr><b>Log</b>\"),\n",
    "    out,\n",
    "    download_area\n",
    "])\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
